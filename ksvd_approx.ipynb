{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "from omp import orthogonal_matching_pursuit_cholensky, orthogonal_matching_pursuit, orthogonal_matching_pursuit_cholensky_batches\n",
    "import cv2\n",
    "from utils import generate_data, extract_blocks, compute_metrics, normalize_image\n",
    "from omp import unsparse, orthogonal_matching_pursuit_cholensky\n",
    "import random\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct2(a):\n",
    "    return scipy.fftpack.dct(scipy.fftpack.dct( a, axis=0, norm='ortho' ), axis=1, norm='ortho' )\n",
    "\n",
    "def idct2(a):\n",
    "    return scipy.fftpack.idct( scipy.fftpack.idct( a, axis=0 , norm='ortho'), axis=1 , norm='ortho')\n",
    "\n",
    "def learn_overcomplete_dictionary(image, block_size=(8, 8), num_atoms=128):\n",
    "    # Extract blocks from image\n",
    "    blocks = extract_blocks(image, block_size)\n",
    "    \n",
    "    # Initialize D_overcomplete matrix\n",
    "    D_overcomplete = np.zeros((block_size[0] * block_size[1], num_atoms))\n",
    "    \n",
    "    # Iterate over blocks to fill D_overcomplete with DCT atoms\n",
    "    for i in range(num_atoms):\n",
    "        # Choose a random block index\n",
    "        random_index = np.random.randint(len(blocks))\n",
    "        block = blocks[random_index]\n",
    "        # Compute DCT of the block\n",
    "        # dct_block = dct2(block.reshape(block_size))\n",
    "        \n",
    "        # # Reshape and store the DCT coefficients as a column in D_overcomplete\n",
    "        # D_overcomplete[:, i] = dct_block.flatten()\n",
    "        D_overcomplete[:, i] = block.flatten()\n",
    "\n",
    "    return D_overcomplete\n",
    "\n",
    "im = Image.open(\"Figures/noisy_image0_noise_lvl25.jpg\")\n",
    "# im = im.resize((256, 256))\n",
    "im_gray = np.array(im.convert('L'))\n",
    "\n",
    "# start with n = 64 (8x8 patches) and K = 6000 (atoms in the dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_gray, cmap='gray')  # cmap='gray' for grayscale image\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data y\n",
    "from utils import generate_data\n",
    "\n",
    "# training patches\n",
    "sparsity_level = 8\n",
    "K = 4000\n",
    "block_size = (8,8) # patch size\n",
    "training_data = generate_data(im_gray, K, block_size) \n",
    "dc_offset = np.mean(training_data)\n",
    "# training_data -= dc_offset\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsity:\n",
    "T0 = 10\n",
    "# sparse coding stage\n",
    "# use any pursuit algorithm to compute represntation vectors xi for each example y1\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "\n",
    "# initialize D\n",
    "D = learn_overcomplete_dictionary(im_gray,  block_size=(8, 8), num_atoms=128)\n",
    "\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksvd(Y, sparsity, initial_D,\n",
    "    maxiter=10, etol=1e-10):\n",
    "    \"\"\"\n",
    "                \n",
    "        Y:       rows hold training data for dictionary fitting\n",
    "        sparsity:   max sparsity of signals. Reduces to K-means\n",
    "                    when sparsity=1\n",
    "        initial_D:  if given, an initial dictionary. Otherwise, random\n",
    "                    rows of data are chosen for initial dictionary\n",
    "        maxiter:    maximum number of iterations\n",
    "        err_thresh: stopping criteria; minimum residual\n",
    "       \n",
    "        \n",
    "        Returns:\n",
    "            D:               learned dictionary\n",
    "            X:               sparse coding of input data\n",
    "            error_norms:     array of training errors for each iteration\n",
    "        Task: find best dictionary D to represent Data Y;\n",
    "              minimize squared norm of Y - DX, constraining\n",
    "              X to sparse codings.\n",
    "    \"\"\"\n",
    "\n",
    "    D = initial_D\n",
    "    D = initial_D / np.linalg.norm(D, axis=0)\n",
    "\n",
    "    # repeat until convergence or stopping criteria    \n",
    "    iterator = tqdm(range(1,maxiter+1))\n",
    "    for iteration in iterator:\n",
    "        # sparse coding stage: estimate columns of X\n",
    "        # omp = OrthogonalMatchingPursuit(n_nonzero_coefs=sparsity)\n",
    "        # Fit the model and obtain the sparse code X\n",
    "        # print(f\"{D.shape=}; {Y.shape=}\")\n",
    "        # X = omp.fit(D, Y).coef_.T\n",
    "        # print(f\"{X.shape=}\")\n",
    "        print(f\"{D.shape=}; {Y.shape=}\")\n",
    "        x, idx = orthogonal_matching_pursuit_cholensky_batches(D, Y, K=sparsity)\n",
    "        # apply the unsparsing along an axes to get an (D.shape[1], x.shape[1] matrix)\n",
    "\n",
    "        X = np.apply_along_axis(unsparse, 0, x, idx, D.shape[1])\n",
    "\n",
    "        # print(f\"{X.shape=}; {D.shape=}; {Y.shape=}\")\n",
    "        # codebook update stage\n",
    "        for j in range(D.shape[1]):\n",
    "            # index set of nonzero components\n",
    "            index_set = np.nonzero(X[j,:])[0]\n",
    "            if len(index_set) == 0:\n",
    "                # for now, replace with some white noise\n",
    "                D[:,j] = np.random.randn(*D[:,j].shape)\n",
    "                D[:,j] = D[:,j] / np.linalg.norm(D[:,j])\n",
    "                continue\n",
    "            \n",
    "            E = Y[:,index_set] - D.dot(X[:,index_set])\n",
    "            D[:,j] = E.dot(X[j,index_set])     # update D\n",
    "           \n",
    "            D[:,j] /= np.linalg.norm(D[:,j])\n",
    "            X[j,index_set] = (E.T).dot(D[:,j]) # update X\n",
    "            \n",
    "        # stopping condition: check error        \n",
    "        err = np.linalg.norm(Y-D.dot(X),'fro')\n",
    "\n",
    "        if err < etol:\n",
    "            break\n",
    "        \n",
    "    return D,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = learn_overcomplete_dictionary(im_gray,  block_size=(8, 8), num_atoms=128) # best (8,8), num_atoms=256\n",
    "D_learned,X = ksvd(training_data.T, initial_D=D, sparsity=16) # best: sparsity=8\n",
    "\n",
    "print(D_learned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting reference patches...\")\n",
    "patch_size = (8, 8)\n",
    "data = extract_patches_2d(im_gray, patch_size)\n",
    "data = data.astype(np.float64)\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "data -= np.mean(data, axis=0)\n",
    "data /= np.std(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_patches = []\n",
    "\n",
    "for i, reference_patch in enumerate(data):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processing reference patch {i + 1}/{len(data)}...\")\n",
    "    \n",
    "    # Apply the OMP algorithm to obtain the sparse representation\n",
    "   \n",
    "    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=4)\n",
    "    # print(f\"{D_overcomplete.shape=}; {reference_patch.shape=}\")\n",
    "    omp.fit(D_learned, reference_patch)\n",
    "    gamma = omp.coef_\n",
    "\n",
    "    # Reconstruct the denoised patch using the sparse representation and the overcomplete dictionary\n",
    "    denoised_patch = D_learned @ gamma.flatten()\n",
    "    \n",
    "    # Add the intercept (mean) to the denoised patch\n",
    "    denoised_patch += np.mean(reference_patch)\n",
    "    \n",
    "    # Append the denoised patch to the list of denoised patches\n",
    "    denoised_patches.append(denoised_patch.reshape(patch_size))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_patches = np.array(denoised_patches) \n",
    "# Assemble the denoised patches into the final denoised image\n",
    "denoised_image_omp = reconstruct_from_patches_2d(denoised_patches, im_gray.shape)\n",
    "# Display the denoised image\n",
    "plt.imshow(denoised_image_omp, cmap='gray')\n",
    "plt.title('Denoised Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize an image array to have values between 0 and 1.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized image array.\n",
    "    \"\"\"\n",
    "    # Normalize the values between 0 and 1\n",
    "    normalized_img = (image - image.min()) / (image.max() - image.min()) * 255\n",
    "    \n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_with_diff(image, reference):\n",
    "    \"\"\"Helper function to display denoising\"\"\"\n",
    "    plt.figure(figsize=(5, 3.3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Image\")\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    difference = image-reference\n",
    "    norm = np.sqrt(np.sum(difference**2))/image.shape[0] / image.shape[1]\n",
    "    plt.title(f\"Difference (norm/pixel): {np.round(norm,3)})\")\n",
    "    plt.imshow(difference,cmap='gray')\n",
    "    # plt.suptitle(title, size=16)\n",
    "    \n",
    "im_clean = Image.open(\"Figures/image2.jpg\")\n",
    "im_clean = np.array(im_clean.convert('L'))\n",
    "denoised_image = normalize_image(denoised_image_omp)\n",
    "\n",
    "im_clean = normalize_image(im_clean)\n",
    "show_with_diff(denoised_image, im_gray)\n",
    "rmse, psnr = compute_metrics(im_clean, denoised_image)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"PSNR: {psnr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_patches = []\n",
    "from omp import orthogonal_matching_pursuit_cholensky, unsparse\n",
    "for i, reference_patch in enumerate(data):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processing reference patch {i + 1}/{len(data)}...\")\n",
    "    \n",
    "    # Apply the OMP algorithm to obtain the sparse representation\n",
    "   \n",
    "    # omp = OrthogonalMatchingPursuit(n_nonzero_coefs=2)\n",
    "    # print(f\"{D_overcomplete.shape=}; {reference_patch.shape=}\")\n",
    "    # omp.fit(D_learned, reference_patch)\n",
    "    # gamma = omp.coef_\n",
    "    x, idx = orthogonal_matching_pursuit_cholensky(D_learned, reference_patch, K=4)\n",
    "    gamma = unsparse(x, idx, D_learned.shape[1])\n",
    "    # Reconstruct the denoised patch using the sparse representation and the overcomplete dictionary\n",
    "    denoised_patch = D_learned @ gamma.flatten()\n",
    "    \n",
    "    # Add the intercept (mean) to the denoised patch\n",
    "    denoised_patch += np.mean(reference_patch)\n",
    "    \n",
    "    # Append the denoised patch to the list of denoised patches\n",
    "    denoised_patches.append(denoised_patch.reshape(patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_patches = np.array(denoised_patches) \n",
    "# Assemble the denoised patches into the final denoised image\n",
    "# data = extract_patches_2d(im_gray, patch_size=(8,8))\n",
    "# denoised_image = reconstruct_from_patches_2d(denoised_patches * np.std(data, axis=0), im_gray.shape)\n",
    "denoised_image_chol = reconstruct_from_patches_2d(denoised_patches, im_gray.shape)\n",
    "# Display the denoised image\n",
    "plt.imshow(denoised_image_chol, cmap='gray')\n",
    "plt.title('Denoised Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_with_diff\n",
    "\n",
    "denoised_image_chol = normalize_image(denoised_image_chol)\n",
    "im_gray = normalize_image(im_gray)\n",
    "show_with_diff(denoised_image_chol, im_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = Image.open(\"Data/example_image_original.jpg\")\n",
    "ground_truth = ground_truth.convert('L') # make it gray\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "im_gray = normalize_image(im_gray)\n",
    "denoised_image_chol = normalize_image(denoised_image_chol)\n",
    "\n",
    "rmse, psnr = compute_metrics(ground_truth, denoised_image_chol)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"PSNR: {psnr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save denoise_image_chol in file\n",
    "im = Image.fromarray(denoised_image_chol)\n",
    "im = im.convert(\"L\")\n",
    "im.save(\"denoised_image_chol.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the image using the learned dictionary\n",
    "lamb = 0.00 # parameter for the regularization term\n",
    "\n",
    "reconstructed = (lamb * im_gray + (1-lamb) * denoised_image) / (1 - lamb)\n",
    "# Display the denoised image\n",
    "plt.imshow(denoised_image, cmap='gray')\n",
    "plt.title('Denoised Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
